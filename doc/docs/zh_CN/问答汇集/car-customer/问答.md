# XXXXXX 环境—平台介绍/使用指导/问题咨询（Intruction/Guide/Solution）

* XXXXXX AG 客户在使用平台时咨询的主要是：
  + 平台中怎么执行模型训练脚本，其中的参数，bash, py 脚本主要的用途和意义；
  + 如何适配到自己的数据集进行模型训练，如数据集格式要求，参数说明；
  + 模型训练、评估、推理的可视化，比较简单的调试方法和工具等，如Mindinsight, Optuna，Neptune AI；
  + 模型文件（代码）导入、导出；
  + 前沿或知名模型的适配支持，比如目标检测常用的SSD, Yolovx， Fast-R-CNN，视频目标跟踪，半监督式异常检测通过对抗性训练GANomely 等；
  + 团队多人使用时的环境隔离，python环境的共享，存储问题等；
  + 如何提高模型训练的精度，优化模型推理结果，如常见参数的配置指导；
  + 如何使用更新Mindspore版本 ！

* 客户使用情况

  + 在6 ~ 9月份持续持续接到了客户的一些咨询，主要通过邮件和teams远程会议，其中Sebastian.Charlet，Alex, Michael直接邮件咨询较多，他们其他同事也要参加teams会议。

  + 平台应该是有多人在使用，运行状态稳定，没有出现异常报错，宕机等需要远程维护的情况。

  + 使用的数据集主要是coco2017 格式，主要有调试数据集puk-cup,实际做训练推理的有：车辆地盘目标数据集，车辆下是否有人的检测数据集；其中puk-cup数据集完整的发给我们，做后续模型的调试；不完整的非常小的车辆地盘目标检测的有问题的数据集。

  + 主要使用的模块是代码开发环境 jupyter-notebook，也引导他们使用模型训教（模板）。

* 客户对平台的关注点简单来讲，如Alex所问：平台在深度学习方面的优势或便捷性。
  *Alex*

  I also would like to ask you for something else. For our documentation, I need to know again the advantages of the Apulis platform in comparison to work without the Apulis platform. I know we already speak about it, but can you send me please a list with the points, what is the value/why is it good to have the Apulis platform (in comparison to work without the Apulis platform)? Or what things the Apulis platform makes easier in working with deep learning? …

## 环境信息（System-Environment)
* MainMission: 主要任务：目标检测模型调优，研究
* Date: 2021-06 ~
* RemoteHost: ——
* OpsAccount: ——
* RemoteMeeting: teams
* SystemInfo: AiArts v1.5.0-rc8
* CANN: 
* Mindspore: 1.1.1
* Tensorflow：1.15
* Pytorch：1.5
* HardwareInfo: 2 node x [Intel(R) Xeon(R) Gold 6230R CPU @ 2.10GHz  2x26 core，503G MEM，2xA910 ，893.8G SSD + 3x1.8T SSD]

## 客户咨询详情(Customer-Requirements):

+ REQ1: 替换为自己的coco数据集执行模型训练

  **Sebastian.Charlet**
  I need some help with the configuration of the Yolo algorithm with my own dataset with two classes. The algorithm is running and I have my dataset labeled in the coco format, but I think I need to change some settings for num_classes, … . Can anyone help me? 

  can you show me again how I can use the yolov4 with my own dataset? I have the dataset already labeled in coco format and the yolov4 algorithm is running as well, but I think I have to finetune some parameters.

+ REQ2: 我们提供的模型是否适应于其他目标的检测

  **Sebastian.Charlet**
  yesterday I saw that in the model-gallery folder, which you send me, that the yolo V3 in TensorFlow you had your own custom pictures (model-gallery\models\npu\tensorflow\yolov3). Does this version or an other algorithm for object detection work right now instead of the YoloV4? 

+ REQ3: 希望在线指导，数据集的格式要求

  **Sebastian.Charlet**
  that is great. I would need some guidance to start with it, so I will send you an invite to a meeting link. Can you check my dataset, that I have send you, if the labelling is correct or I need to relabel it in another format? 

+ REQ4: 提高模型检测精准度（推理参数）

  **Sebastian.Charlet**
  thank you very much for your guide. I just trained my model and I think we need to finetune the configuration more. 

  •	In the default_config.yaml I needed to change the line 108 as well, because otherwise I get an error (see attached error.txt) 
  •	After this change I could start training, but my loss did not improve it went down really good, but after 2 iterations the loss stayed at around 60-70 (see attached loss.txt). Should I increase the epoch number? The loss should be around 2-3.  
  •	Could my backbone be a problem? (download my version here: https://we.tl/t-xPlRLidkRv) Could you provide your backbone to me? 
  •	Finally after training I checked my results and the trained model did not recognize my cup nor the puck (as reference with another trained yolov4 model see attached result.pdf)

  Do you know how I could improve my accuracy for the model? 

+ REQ5: 如何优化训练参数，提高模型精度（我们询问了他是怎么提高模型精度的）

  **Sebastian.Charlet**

  first of all thank you all very much for your help! Since you send me your mail earlier today, I tweaked and changed some more settings and finally the algorithm is running and I get the loss under 30 in training. One main factor was the backbone, with yours it is already working better, secondly I decreased the learning rate from 0.1 to 0.001 and increased the epochs to 640. So I can have a threshold of 0.8 and it detects both the puck and the cup correctly (attached results.pdf). I think tweaking the learning rate and epochs more will get me a better performing network. 

+ REQ6: 推理结果中，不同类型标签的检测框和置信度，使用不同的颜色

  **Sebastian.Charlet**

  Could you add two things to the infer.ipynb so, that every bounding box for each class has a different color and above or below the bounding box should stay the predicted class with its percentage. And is it possible to download the predicted picture?  

+ REQ7: 如何切换其他多类标签的数据集

  **Sebastian.Charlet**

  thank you for the updated infer file. I switched my training pictures to detect the underbody of the cars and with the infer file now it occurs an error. All important files and description of the error are in die link (https://we.tl/t-OANOmOkhLT). It worked with the two classes, now I want to detect four different classes, do you know how I could get a solution? 

+ REQ8: 评估结果的可视化展示

  **Sebastian.Charlet**
  the network is working great now, thanks again for your help. Is it possible to export a chart like the one attached to evaluate the model and is it possible to export a confusion matrix? 

  Currently I only work with the yolov4 model. Is it possible with this to get a confusion matrix like to get an overview about the TP/TN/FP/FN of the validation data? 

+ REQ9: 模型代码脚本怎么理解，怎么创建自己的模型

  **Alex**
  I got some programming code what I would like to understand and what I need to create an own model, but I will show you in the meeting!

+ REQ10: 模型下载或导出

  **Alex**
  The model training in Apulis, that we did in the end, was successful! Do you know, how it is now possible to get / download the trained model?

+ REQ11: 多人共用环境问题(环境隔离)，他们同事共用admin账户，Alex独自安装了mindspore1.3.0 x86 GPU版本，导致同事Michael的模型GANomely执行报错
  **Alex**
  we need your help for an emergency please! Accidentally I started to run the command 

  !pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.2.1/MindSpore/gpu/ubuntu_x86/cuda-10.1/mindspore_gpu-1.2.1-cp37-cp37m-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple

  In combination with the command

  context.set_context(device_target="GPU")

  in a Jupyter Notebook file in Jupyter Lab from Apulis what started to install accidentally the MindSpore version 1.2.1 for using GPU. In the process of this installation I stopped it, but there happened already some changes on the system that created some errors. We tried to delete this new version again, but the changes on the system not disappeared. Also we deleted MindSpore completely and tried to install it again, but it was not possible to install a MindSpore version for us, not even the install verification worked.

  Can you help us please to install MindSpore again (maybe it is possible to install now the newest version 1.3.0?) and help that the system works again? It is a little bit urgent for us because my collegues can not work now.

  ***环境隔离，pip virtualenv 或conda可以避免类似问题***

  *需要卸载后清理pip缓存*

  RuntimeError: mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95 KernelQueryAll] NotExistsError Failed to obtain operator info, Please check whether the operator info is registered, Op full name:Default/AdamNoUpdateParam-op1412Node Type: AdamNoUpdateParam, Node DebugString: kernel_graph_162:[CNode]0{[0]: ValueNode<PrimitivePy> AdamNoUpdateParam, [1]: [Parameter]1, [2]: [Parameter]2, [3]: [Parameter]3, [4]: [Parameter]4, [5]: [Parameter]5, [6]: [Parameter]6, [7]: [Parameter]7, [8]: [Parameter]8, [9]: [Parameter]9}
  trace:

  **Michael Jupke**
  I’ll try and inform you.

  Just a question for clearance: I create a code development and install some pip packages. Afterward I delete the code development and create a new one. Are the installed packages part of the new code development?

+ REQ12: 平台偶现不能登陆

  are you currently working on the platform? Three hours ago I uploaded two small zip files and shortly after the start of the upload I got an  connection error and I still cant connect to the platform. So is it normal or is there an other error? 

+ REQ13: mindspore升级或兼容性

  **Michael Jupke**
  I got it,  the Mindspore version should match with the hardware and the ascend toolkit. Alex accidently installed a mindspore-gpu version. And then there were a lot of problems. Is it working again?

  Second point: You’re right. I know the ops.Add function, and didn’t see that the verification step says ops.add(). Maybe we should instead use this example: https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Add.html#mindspore.ops.Add

  Some additionally points from my side:
  -	Is it possible to use a newer version of mindspore? For example 1.2.1? Do you have to upgrade the ascend toolkit or any firmware for this? For me version 1.1.1 is ok, but meanwhile the new version has a lot of more features. I just saw that the modelzoo repository in gitee is also using mindspore 1.3.0.
  -	I think using the docker image with the jupyter, mindspore, pip stuff in a sandbox mode can prevent such problems. Also software dependency problems for additionally python libs can be prevented. Imagine multiple users working with different tools which are not compatible with each other.

+ REQ14: 视频目标跟踪

  **Sebastian.Charlet**

  I would like to infer a video as .mov file with my algorithm. Do you know what parameter I need to change within the infer.ipynb to work with this file? 

+ REQ15: 其他目标检测模型

  **Sebastian.Charlet**
  the YOLOv4 algorithm is working great. Now I would like to try another algorithm with my dataset. Can you recommend me a working algorithm like the r-cnn, sppnet, fast rcnn that I could use on the platform? 
  我们推荐了Fast-R-CNN，SSD ;但最后只有SSD 跑通了训练，评估和推理；bash/python 脚本封装的不太好，找了多个版本的脚本才调试起来。


+ REQ15: 存储IO，AutoDL, 超参调优；使用第三方工具（ Optuna， Neptune AI）

  **Michael Jupke**
  currently I have some trouble with Disk I/O Errors in Code Developments.
  I have noticed this problem with two separate programs.

  First Neptune AI. This provider offers simple tracking of the training process. To connect to the web service there is a Python package that implements the data transfer to Neptune AI. By default this program uses a cache (a hidden folder .neptune/ in the corresponding project directory). If there is no internet connection at the moment, the data will be cached longer and uploaded afterwards. This works quite well so far. However, for the cache system files are created in the hidden folder and deleted again after successful upload. This asynchronous procedure is sometimes so fast that the file can not be deleted with os.remove(), because it does not exist yet, or is not visible, writable, whatever. 

  The second application is Optuna. This is used for hyperparameter optimization. In order not to lose the results and set parameters in case of an error, they can be stored in a sqlite3 database at runtime. The database file is again located in the project directory. After a certain time the disk I/O error occurs when accessing the database (see screenshot). 

  I suspect that these errors have a common reason, which lies in the Kubenetes technique to share a file system. I assume you are using pods to connect multiple containers to a shared storage and network resource. Unfortunately I am a amateur in this area but in the context of sqlite3 Connection, for example, there are also problems if the database file is on a cloud like Onedrive.  See: https://stackoverflow.com/questions/47540607/disk-i-o-error-with-sqlite3-in-python-3-when-writing-to-a-database

  I think there is room for improvement in this regard. Maybe it's just a configuration thing. 
  If you know a workaround, please let me know. Thank you!



## Install mindinsight

git clone https://gitee.com/mindspore/mindinsight.git   

```bash
pip install --upgrade pip && pip3 install $MINDINSIGHT_PKG && \
&& sed -i "/^HOST/cHOST = '0.0.0.0'" /usr/local/lib/python3.7/site-packages/mindinsight/conf/constants.py
```

vim /home/admin/.local/lib/python3.7/site-packages/mindinsight/conf/constants.py


python -m mindinsight start  --port 48080 --summary-base-dir /home/admin/yolov4-fc/yolov4-infer/summary_dir

python -m mindinsight stop

TARGET=infer

TARGET=mindinsight
sudo ps -ef | grep ${TARGET} | grep -v grep | awk '{print $2}' | xargs kill -9


```yml
{
  "created_at": "2021-01-06 11:35:29",
  "updated_at": "2021-01-06 11:35:29",
  "version": "0.0.1",
  "status": "normal",
  "models": [
    {
      "name": "YOLOv4_mindspore_npu_scratch",
      "description": "YOLOv4_mindspore_npu_scratch",
      "size": "51000000",
      "use": "ObjectDetection",
      "dataset": {
        "name": "coco2017",
        "path": "coco/2017/raw",
        "format": "Image",
        "size": "1671368100",
        "description": "coco2017"
      },
      "params": {
        "learning_rate": "0.1",
        "batch_size": "32",
        "epoch_size": "320"
      },
      "engine": "apulistech/mindspore-nni-npu:1.1.1-20.2-arm",
      "precision": "-",
      "output_path": "work_dirs/YOLOv4_mindspore_npu_scratch",
      "startup_file": "train.sh",
      "device_type": "huawei_npu_arm64",
      "device_num": 1
    }
  ]
}

```

tar cf [YOUR-DIRECTORY]/yolov4

Linux 6c42538d-8201-4fd9-96e1-080bf6693c63 4.15.0-29-generic #31-Ubuntu SMP Tue Jul 17 15:39:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
bash: nvidia-smi: command not found

+------------------------------------------------------------------------------------+
| npu-smi 1.8.11                   Version: 20.2.0                                   |
+----------------------+---------------+---------------------------------------------+
| NPU   Name           | Health        | Power(W)   Temp(C)                          |
| Chip                 | Bus-Id        | AICore(%)  Memory-Usage(MB)  HBM-Usage(MB)  |
+======================+===============+=============================================+
| 4     910A           | OK            | 65.4       46                               |
| 0                    | 0000:86:00.0  | 0          2170 / 15505      0    / 32255   |
+======================+===============+=============================================+
python -c "import mindspore;mindspore.run_check()"


Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/__init__.py", line 17, in <module>
    from .run_check import run_check
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/run_check/__init__.py", line 18, in <module>
    from ._check_version import check_version_and_env_config
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/run_check/_check_version.py", line 431, in <module>
    check_version_and_env_config()
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/run_check/_check_version.py", line 415, in check_version_and_env_config
    env_checker.check_env(e)
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/run_check/_check_version.py", line 263, in check_env
    raise e
  File "/home/admin/.local/lib/python3.7/site-packages/mindspore/run_check/_check_version.py", line 412, in check_version_and_env_config
    from .. import _c_expression # pylint: disable=unused-import
ImportError: libopt_feature.so: cannot open shared object file: No such file or directory

import numpy as np
from mindspore import Tensor
import mindspore.ops as ops
import mindspore.context as context

context.set_context(device_target="Ascend")
x = Tensor(np.ones([1,3,3,4]).astype(np.float32))
y = Tensor(np.ones([1,3,3,4]).astype(np.float32))
print(ops.add(x, y))

RuntimeError: mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95 KernelQueryAll] NotExistsError Failed to obtain operator info, Please check whether the operator info is registered, Op full name:Default/AdamNoUpdateParam-op1412Node Type: AdamNoUpdateParam, Node DebugString: kernel_graph_162:[CNode]0{[0]: ValueNode<PrimitivePy> AdamNoUpdateParam, [1]: [Parameter]1, [2]: [Parameter]2, [3]: [Parameter]3, [4]: [Parameter]4, [5]: [Parameter]5, [6]: [Parameter]6, [7]: [Parameter]7, [8]: [Parameter]8, [9]: [Parameter]9}
trace:

## 总体使用感受

奥迪现在主要还是用自己的数据训练模型，

总体上可以AIstudio v1.0的实验管理，模型工厂，可视化训练（mindinsight）为基础，超参调优，模型发布，中心推理，资源监控为主。

平台对DL的提升之处： 
1. 数据、模型、推理任务的项目管理（他们对环境，数据集还是比较重视的，以项目或实验概念管理模型训练任务）
2. 模型训练的便捷性：模型迁移，训练模板，训练参数复用，（能解决前几次他们尝试替换数据集，调整模型精度的困难）
3. 资源高效利用：（他们至少是一个团队在使用，必然存在资源分配的痛点）
4. 训练可视化：（如果是本地环境，比如jupyter就需要自己安装工具，自己可视化代码，日志分析代码，平台可以原生的解决这个痛点）
5. 最后训练环境的运维，长期的技术协助。（华为的AI昇腾生态刚刚起步，很多不完善的地方，我们平台直接解决了环境配置运维的痛点）

