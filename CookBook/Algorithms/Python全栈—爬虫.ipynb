{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬虫相关\n",
    "\n",
    "138.在 requests 模块中，requests.content 和 requests.text 什么区别\n",
    "139.简要写一下 lxml 模块的使用方法框架\n",
    "140.说一说 scrapy 的工作流程\n",
    "141.scrapy 的去重原理\n",
    "142.scrapy 中间件有几种类，你用过哪些中间件\n",
    "143.你写爬虫的时候都遇到过什么？反爬虫措施，你是怎么解决的？\n",
    "144.为什么会用到代理？\n",
    "145.代理失效了怎么处理？\n",
    "146.列出你知道 header 的内容以及信息\n",
    "147.说一说打开浏览器访问 www.baidu.com 获取到结果，整个流程。\n",
    "148.爬取速度过快出现了验证码怎么处理\n",
    "149.scrapy 和 scrapy-redis 有什么区别？为什么选择 redis 数据库？\n",
    "150.分布式爬虫主要解决什么问题\n",
    "151.写爬虫是用多进程好？还是多线程好？ 为什么？\n",
    "152.解析网页的解析器使用最多的是哪几个\n",
    "153.需要登录的网页，如何解决同时限制 ip，cookie,session（其中有一些是动态生成的）在不使用动态爬取的情况下？\n",
    "154.验证码的解决（简单的：对图像做处理后可以得到的，困难的：验证码是点击，拖动等动态进行的？）\n",
    "155.使用最多的数据库（mysql，mongodb，redis 等），对他的理解？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
